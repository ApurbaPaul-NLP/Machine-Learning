{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP9OxB+uby9fssx1UjA2Wof",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ApurbaPaul-NLP/Machine-Learning/blob/main/02_09_2022_Tokenizing_text_and_creating_sequences_for_sentences.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "EqGcZFFlIKhT"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = [\n",
        "    'My favorite food is ice cream',\n",
        "    'do you like ice cream too?',\n",
        "    'My dog likes ice cream!',\n",
        "    \"your favorite flavor of icecream is chocolate\",\n",
        "    \"chocolate isn't good for dogs\",\n",
        "    \"your dog, your cat, and your parrot prefer broccoli\"\n",
        "]"
      ],
      "metadata": {
        "id": "MS4vqN9fI1I-"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Optionally set the max number of words to tokenize.\n",
        "# The out of vocabulary (OOV) token represents words that are not in the index.\n",
        "# Call fit_on_text() on the tokenizer to generate unique numbers for each word\n",
        "tokenizer = Tokenizer(num_words = 100, oov_token=\"<OOV>\")\n",
        "tokenizer.fit_on_texts(sentences)"
      ],
      "metadata": {
        "id": "QwXJE1d2I8As"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Examine the word index\n",
        "word_index = tokenizer.word_index\n",
        "print(word_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WpQeGMECI_iX",
        "outputId": "a2ec6c5c-b24c-48bf-f177-4c1fc7216e02"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'<OOV>': 1, 'your': 2, 'ice': 3, 'cream': 4, 'my': 5, 'favorite': 6, 'is': 7, 'dog': 8, 'chocolate': 9, 'food': 10, 'do': 11, 'you': 12, 'like': 13, 'too': 14, 'likes': 15, 'flavor': 16, 'of': 17, 'icecream': 18, \"isn't\": 19, 'good': 20, 'for': 21, 'dogs': 22, 'cat': 23, 'and': 24, 'parrot': 25, 'prefer': 26, 'broccoli': 27}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the number for a given word\n",
        "print(word_index['favorite'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NCT_LBlyJCbk",
        "outputId": "00e1e1dd-c86d-4e90-a710-bf7740a5bd4e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sequences = tokenizer.texts_to_sequences(sentences)\n",
        "print (sequences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ukTKkjCqJlNc",
        "outputId": "2a64baa1-28c3-461f-e10f-79f04da8e2f3"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[5, 6, 10, 7, 3, 4], [11, 12, 13, 3, 4, 14], [5, 8, 15, 3, 4], [2, 6, 16, 17, 18, 7, 9], [9, 19, 20, 21, 22], [2, 8, 2, 23, 24, 2, 25, 26, 27]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentences2 = [\"I like hot chocolate\", \"My dogs and my hedgehog like kibble but my squirrel prefers grapes and my chickens like ice cream, preferably vanilla\"]\n",
        "\n",
        "sequences2 = tokenizer.texts_to_sequences(sentences2)\n",
        "print(sequences2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oo9bfdbuJv0s",
        "outputId": "fbda3c2d-a45f-4021-9615-ccc8f9360e06"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1, 13, 1, 9], [5, 22, 24, 5, 1, 13, 1, 1, 5, 1, 1, 1, 24, 5, 1, 13, 3, 4, 1, 1]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "metadata": {
        "id": "tq2Eds8VMLvP"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(sentences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zfeVb2eSMU7U",
        "outputId": "f0b9e2d6-cabd-477f-c495-068534c529f2"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['My favorite food is ice cream', 'do you like ice cream too?', 'My dog likes ice cream!', 'your favorite flavor of icecream is chocolate', \"chocolate isn't good for dogs\", 'your dog, your cat, and your parrot prefer broccoli']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer(num_words = 100, oov_token=\"<OOV>\")"
      ],
      "metadata": {
        "id": "b3cXmXZ0MYo8"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.fit_on_texts(sentences)\n",
        "word_index = tokenizer.word_index\n",
        "print(word_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j5pUdOX_MalM",
        "outputId": "ca3f5f26-006d-412c-d0cf-96487b304cea"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'<OOV>': 1, 'your': 2, 'ice': 3, 'cream': 4, 'my': 5, 'favorite': 6, 'is': 7, 'dog': 8, 'chocolate': 9, 'food': 10, 'do': 11, 'you': 12, 'like': 13, 'too': 14, 'likes': 15, 'flavor': 16, 'of': 17, 'icecream': 18, \"isn't\": 19, 'good': 20, 'for': 21, 'dogs': 22, 'cat': 23, 'and': 24, 'parrot': 25, 'prefer': 26, 'broccoli': 27}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sequences = tokenizer.texts_to_sequences(sentences)\n",
        "print (sequences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_oaFKSMnMcK6",
        "outputId": "7876b873-d719-4263-af9e-7c0045982cf6"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[5, 6, 10, 7, 3, 4], [11, 12, 13, 3, 4, 14], [5, 8, 15, 3, 4], [2, 6, 16, 17, 18, 7, 9], [9, 19, 20, 21, 22], [2, 8, 2, 23, 24, 2, 25, 26, 27]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "padded = pad_sequences(sequences)\n",
        "print(\"\\nWord Index = \" , word_index)\n",
        "print(\"\\nSequences = \" , sequences)\n",
        "print(\"\\nPadded Sequences:\")\n",
        "print(padded)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "POHNGPlnMeFS",
        "outputId": "a4a40f31-2f69-4298-9004-d795d35c586c"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Word Index =  {'<OOV>': 1, 'your': 2, 'ice': 3, 'cream': 4, 'my': 5, 'favorite': 6, 'is': 7, 'dog': 8, 'chocolate': 9, 'food': 10, 'do': 11, 'you': 12, 'like': 13, 'too': 14, 'likes': 15, 'flavor': 16, 'of': 17, 'icecream': 18, \"isn't\": 19, 'good': 20, 'for': 21, 'dogs': 22, 'cat': 23, 'and': 24, 'parrot': 25, 'prefer': 26, 'broccoli': 27}\n",
            "\n",
            "Sequences =  [[5, 6, 10, 7, 3, 4], [11, 12, 13, 3, 4, 14], [5, 8, 15, 3, 4], [2, 6, 16, 17, 18, 7, 9], [9, 19, 20, 21, 22], [2, 8, 2, 23, 24, 2, 25, 26, 27]]\n",
            "\n",
            "Padded Sequences:\n",
            "[[ 0  0  0  5  6 10  7  3  4]\n",
            " [ 0  0  0 11 12 13  3  4 14]\n",
            " [ 0  0  0  0  5  8 15  3  4]\n",
            " [ 0  0  2  6 16 17 18  7  9]\n",
            " [ 0  0  0  0  9 19 20 21 22]\n",
            " [ 2  8  2 23 24  2 25 26 27]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Specify a max length for the padded sequences\n",
        "padded = pad_sequences(sequences, maxlen=15)\n",
        "print(padded)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w3gAq9ESMhmq",
        "outputId": "c3843bc4-3d18-40ea-dc4d-f92528d40d8c"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0  0  0  0  0  0  0  0  0  5  6 10  7  3  4]\n",
            " [ 0  0  0  0  0  0  0  0  0 11 12 13  3  4 14]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  5  8 15  3  4]\n",
            " [ 0  0  0  0  0  0  0  0  2  6 16 17 18  7  9]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  9 19 20 21 22]\n",
            " [ 0  0  0  0  0  0  2  8  2 23 24  2 25 26 27]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Put the padding at the end of the sequences\n",
        "padded = pad_sequences(sequences, maxlen=15, padding=\"post\")\n",
        "print(padded)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NmE2cWBlMjqE",
        "outputId": "68e0f526-fd91-45a0-e816-13337db67d6b"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 5  6 10  7  3  4  0  0  0  0  0  0  0  0  0]\n",
            " [11 12 13  3  4 14  0  0  0  0  0  0  0  0  0]\n",
            " [ 5  8 15  3  4  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 2  6 16 17 18  7  9  0  0  0  0  0  0  0  0]\n",
            " [ 9 19 20 21 22  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 2  8  2 23 24  2 25 26 27  0  0  0  0  0  0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Limit the length of the sequences, you will see some sequences get truncated\n",
        "padded = pad_sequences(sequences, maxlen=3)\n",
        "print(padded)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sy4fvN51MlfA",
        "outputId": "46303d09-8bc9-4794-e800-dfd84018702a"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 7  3  4]\n",
            " [ 3  4 14]\n",
            " [15  3  4]\n",
            " [18  7  9]\n",
            " [20 21 22]\n",
            " [25 26 27]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **What happens if some of the sentences contain words that are not in the word index?**"
      ],
      "metadata": {
        "id": "QDNCY3FXMpFg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Try turning sentences that contain words that \n",
        "# aren't in the word index into sequences.\n",
        "# Add your own sentences to the test_data\n",
        "test_data = [\n",
        "    \"my best friend's favorite ice cream flavor is strawberry\",\n",
        "    \"my dog's best friend is a manatee\"\n",
        "]\n",
        "print (test_data)\n",
        "\n",
        "# Remind ourselves which number corresponds to the\n",
        "# out of vocabulary token in the word index\n",
        "print(\"<OOV> has the number\", word_index['<OOV>'], \"in the word index.\")\n",
        "\n",
        "# Convert the test sentences to sequences\n",
        "test_seq = tokenizer.texts_to_sequences(test_data)\n",
        "print(\"\\nTest Sequence = \", test_seq)\n",
        "\n",
        "# Pad the new sequences\n",
        "padded = pad_sequences(test_seq, maxlen=10)\n",
        "print(\"\\nPadded Test Sequence: \")\n",
        "\n",
        "# Notice that \"1\" appears in the sequence wherever there's a word \n",
        "# that's not in the word index\n",
        "print(padded)"
      ],
      "metadata": {
        "id": "Mzmbob9SMpwT",
        "outputId": "42a858f0-5c2f-40cb-a2d0-17198e858a24",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\"my best friend's favorite ice cream flavor is strawberry\", \"my dog's best friend is a manatee\"]\n",
            "<OOV> has the number 1 in the word index.\n",
            "\n",
            "Test Sequence =  [[5, 1, 1, 6, 3, 4, 16, 7, 1], [5, 1, 1, 1, 7, 1, 1]]\n",
            "\n",
            "Padded Test Sequence: \n",
            "[[ 0  5  1  1  6  3  4 16  7  1]\n",
            " [ 0  0  0  5  1  1  1  7  1  1]]\n"
          ]
        }
      ]
    }
  ]
}